# -*- coding: utf-8 -*-
"""Aidetector3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uk9r7baMrFlmeRZl7mIbSbbpmvrBSKve
"""

"""
Improved AI Text Detector - Training Script for NabeelShar/ai_and_human_text
This script trains a model to detect AI-generated text using the NabeelShar/ai_and_human_text dataset
"""


# Install required packages
# pip install transformers datasets pandas scikit-learn torch numpy tqdm matplotlib

# Import libraries
import numpy as np
import pandas as pd
from datasets import load_dataset
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import (
    DistilBertTokenizer,
    DistilBertForSequenceClassification,
    TrainingArguments,
    Trainer,
    TrainerCallback
)
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
from sklearn.model_selection import train_test_split
import random
from tqdm.auto import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
import time
import os
import zipfile

# Set random seeds for reproducibility
torch.manual_seed(42)
random.seed(42)
np.random.seed(42)

# Load the dataset
print("Loading dataset...")
dataset = load_dataset("NabeelShar/ai_and_human_text")
print("Dataset loaded successfully!")

# Check transformers version
import transformers
print(f"Transformers version: {transformers.__version__}")

# Convert the dataset to pandas DataFrame for easier manipulation
df = pd.DataFrame(dataset['train'])
print(f"\nOriginal dataset size: {len(df)} rows")

# Display column information
print(f"Columns in dataset: {df.columns.tolist()}")
print(f"Distribution of 'generated' values: {df['generated'].value_counts().to_dict()}")

# Create our own train/validation/test splits (80/10/10)
# First split: 80% train, 20% temp (for val+test)
train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['generated'])

# Second split: divide temp into half validation, half test (each 10% of original)
val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['generated'])

print(f"\nDataset splits:")
print(f"Training: {len(train_df)} rows")
print(f"Validation: {len(val_df)} rows")
print(f"Test: {len(test_df)} rows")

# Check class distribution in each split
print("\nLabel distribution:")
print(f"Training: {train_df['generated'].value_counts().to_dict()}")
print(f"Validation: {val_df['generated'].value_counts().to_dict()}")
print(f"Test: {test_df['generated'].value_counts().to_dict()}")

# Create a custom dataset class
class AITextDetectionDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=512):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = int(self.labels[idx])  # Ensure label is integer

        encoding = self.tokenizer(
            text,
            truncation=True,
            max_length=self.max_length,
            padding="max_length",
            return_tensors="pt"
        )

        # Remove the batch dimension added by tokenizer
        encoding = {k: v.squeeze(0) for k, v in encoding.items()}
        encoding['labels'] = torch.tensor(label, dtype=torch.long)

        return encoding

# Initialize tokenizer
tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")

# Function to prepare data for training
def prepare_data_from_dataset(dataset):
    """Prepare the data from the loaded dataset"""
    texts = dataset['text'].tolist()
    labels = dataset['generated'].tolist()

    # Print distribution of labels
    label_counts = pd.Series(labels).value_counts().to_dict()
    print(f"Label distribution: {label_counts}")

    # Calculate and print some statistics about text lengths
    text_lengths = [len(text) for text in texts]
    token_lengths = [len(tokenizer.tokenize(text[:1000])) for text in texts[:100]]  # Sample for speed

    print(f"Text length stats:")
    print(f"  Min: {min(text_lengths)} chars")
    print(f"  Max: {max(text_lengths)} chars")
    print(f"  Avg: {sum(text_lengths)/len(text_lengths):.1f} chars")
    print(f"Estimated token length (from sample):")
    print(f"  Min: {min(token_lengths)} tokens")
    print(f"  Max: {max(token_lengths)} tokens")
    print(f"  Avg: {sum(token_lengths)/len(token_lengths):.1f} tokens")

    return texts, labels

# Quick exploratory analysis on some examples
print("\nExploring sample texts from the dataset:")
print("-" * 80)
human_samples = df[df['generated'] == 0].sample(2)['text'].values
ai_samples = df[df['generated'] == 1].sample(2)['text'].values

print("Human text examples:")
for i, text in enumerate(human_samples):
    print(f"Example {i+1}: {text[:200]}..." if len(text) > 200 else f"Example {i+1}: {text}")
    print()

print("AI-generated text examples:")
for i, text in enumerate(ai_samples):
    print(f"Example {i+1}: {text[:200]}..." if len(text) > 200 else f"Example {i+1}: {text}")
    print()
print("-" * 80)

# Show distribution of prompt names
print("\nPrompt name distribution:")
prompt_counts = df['prompt_name'].value_counts()
print(prompt_counts)

# Prepare the data
print("\nPreparing training data:")
train_texts, train_labels = prepare_data_from_dataset(train_df)

print("\nPreparing validation data:")
val_texts, val_labels = prepare_data_from_dataset(val_df)

print("\nPreparing test data:")
test_texts, test_labels = prepare_data_from_dataset(test_df)

# Create datasets
train_dataset = AITextDetectionDataset(train_texts, train_labels, tokenizer)
val_dataset = AITextDetectionDataset(val_texts, val_labels, tokenizer)
test_dataset = AITextDetectionDataset(test_texts, test_labels, tokenizer)

# Storage for metrics to plot later
training_metrics = {
    'steps': [],
    'loss': [],
    'eval_steps': [],
    'eval_accuracy': [],
    'eval_f1': []
}

# Define metrics function
def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')
    acc = accuracy_score(labels, preds)

    # Log metrics to our tracking dictionary
    step = len(training_metrics['eval_steps'])
    training_metrics['eval_steps'].append(step)
    training_metrics['eval_accuracy'].append(acc)
    training_metrics['eval_f1'].append(f1)

    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

# Define custom callback for tracking training loss
class LoggingCallback(TrainerCallback):
    def on_log(self, args, state, control, logs=None, **kwargs):
        if logs:
            if 'loss' in logs:
                training_metrics['steps'].append(state.global_step)
                training_metrics['loss'].append(logs['loss'])

# Initialize model
print("\nInitializing model...")
model = DistilBertForSequenceClassification.from_pretrained(
    "distilbert-base-uncased",
    num_labels=2
)

# Calculate appropriate steps based on dataset size
train_size = len(train_df)
batch_size = 16
steps_per_epoch = train_size // batch_size
eval_steps = max(steps_per_epoch // 5, 1)  # Evaluate ~5 times per epoch
save_steps = eval_steps
logging_steps = max(steps_per_epoch // 10, 1)  # Log ~10 times per epoch

print(f"\nTraining configuration:")
print(f"Steps per epoch: ~{steps_per_epoch}")
print(f"Evaluation every {eval_steps} steps")
print(f"Logging every {logging_steps} steps")

# Define training arguments
training_args = TrainingArguments(
    output_dir="./results",
    eval_strategy="steps",         # Evaluate during training
    eval_steps=eval_steps,         # Evaluate several times per epoch
    save_strategy="steps",
    save_steps=save_steps,
    learning_rate=3e-5,            # Slightly higher learning rate for small dataset
    per_device_train_batch_size=batch_size,
    per_device_eval_batch_size=batch_size,
    num_train_epochs=1,            # Train for 3 epochs
    weight_decay=0.01,
    load_best_model_at_end=True,
    metric_for_best_model="f1",
    report_to="none",              # Disable wandb
    logging_steps=logging_steps,
    warmup_ratio=0.1,              # Warmup for first 10% of training
    fp16=False                     # Disable mixed precision to avoid issues
)

# Initialize trainer with callback
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    callbacks=[LoggingCallback()],
)

# Train the model
print("\nTraining model...")
start_time = time.time()
trainer.train()
training_time = time.time() - start_time
print(f"\nTraining completed in {training_time/60:.2f} minutes")

# Evaluate the model on validation set
print("\nEvaluating model on validation set...")
eval_results = trainer.evaluate()
print(f"Validation results: {eval_results}")

# Evaluate on test set
print("\nEvaluating model on test set...")
test_results = trainer.evaluate(test_dataset)
print(f"Test results: {test_results}")

# Get predictions on test set for confusion matrix
test_trainer = Trainer(
    model=model,
    args=TrainingArguments(output_dir="./temp", report_to="none"),
    compute_metrics=compute_metrics,
)
test_predictions = test_trainer.predict(test_dataset)
test_preds = test_predictions.predictions.argmax(-1)

# Create confusion matrix
cm = confusion_matrix(test_labels, test_preds)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Human', 'AI'],
            yticklabels=['Human', 'AI'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.savefig('confusion_matrix.png')

# Save the model
print("\nSaving model...")
model.save_pretrained("./improved_ai_detector_model")
tokenizer.save_pretrained("./improved_ai_detector_model")

# Zip the model for download
print("\nPreparing model for download...")
def zipdir(path, ziph):
    # Zip the directory
    for root, dirs, files in os.walk(path):
        for file in files:
            ziph.write(os.path.join(root, file),
                       os.path.relpath(os.path.join(root, file),
                                       os.path.join(path, '..')))

with zipfile.ZipFile('improved_ai_detector_model.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:
    zipdir('./improved_ai_detector_model', zipf)

# Plot training metrics
plt.figure(figsize=(15, 10))

# Plot 1: Training loss
plt.subplot(2, 1, 1)
plt.plot(training_metrics['steps'], training_metrics['loss'])
plt.title('Training Loss')
plt.xlabel('Steps')
plt.ylabel('Loss')
plt.grid(True)

# Plot 2: Evaluation metrics
plt.subplot(2, 1, 2)
plt.plot(training_metrics['eval_steps'], training_metrics['eval_accuracy'], label='Accuracy')
plt.plot(training_metrics['eval_steps'], training_metrics['eval_f1'], label='F1 Score')
plt.title('Evaluation Metrics')
plt.xlabel('Evaluation Steps')
plt.ylabel('Score')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.savefig('training_metrics.png')
plt.show()

# Create a function to test the model on custom examples
def test_model_prediction(model, tokenizer, text, temperature=1.0):
    """Test the model on a text example with temperature scaling"""
    # Check if GPU is available and move everything to the same device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)  # Make sure model is on the right device

    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
    # Move input tensors to the same device as the model
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
        # Apply temperature scaling
        predictions = torch.softmax(outputs.logits / temperature, dim=-1)

    human_probability = predictions[0][0].item()
    ai_probability = predictions[0][1].item()
    result = "AI-generated" if ai_probability > 0.5 else "Human-written"

    return result, human_probability, ai_probability

# Test the model on a variety of examples
print("\nTesting model on some interesting examples...")

test_examples = [
    # Well-written academic human text
    {
        "text": "The ontological implications of quantum mechanics challenge our traditional understanding of reality. When we consider the wave-particle duality and quantum superposition, we must reconsider what it means for an object to 'exist' in a determinate state.",
        "expected": "Human"
    },
    # Simple human text
    {
        "text": "I went to the store yesterday. It was raining so I got wet. I bought some milk and bread. The cashier was friendly.",
        "expected": "Human"
    },
    # AI-generated technical explanation
    {
        "text": "Large Language Models (LLMs) operate on a transformer architecture that employs self-attention mechanisms to process sequential data. These models are trained using unsupervised learning on vast corpora, enabling them to predict subsequent tokens based on preceding context.",
        "expected": "AI"
    },
    # AI text with simple language
    {
        "text": "Dogs are pets that many people love. They come in different sizes and colors. Some dogs are big, and some are small. They like to play with toys and go for walks.",
        "expected": "AI"
    }
]

# Set temperature for prediction
temperature = 2.0  # Higher temperature for smoother probabilities

print(f"\nModel predictions (with temperature={temperature}):")
print("-" * 80)
for i, example in enumerate(test_examples):
    result, human_prob, ai_prob = test_model_prediction(model, tokenizer, example["text"], temperature)
    print(f"Example {i+1} ({example['expected']}):")
    print(f"Text: {example['text'][:100]}..." if len(example['text']) > 100 else f"Text: {example['text']}")
    print(f"Prediction: {result}")
    print(f"Human probability: {human_prob:.4f}, AI probability: {ai_prob:.4f}")
    print("-" * 80)

print("\nModel training and evaluation complete!")
print("You can now download the following files:")
print("1. improved_ai_detector_model.zip - Your trained model")
print("2. training_metrics.png - Graph of training progress")
print("3. confusion_matrix.png - Confusion matrix on test set")

# Additional analysis: Performance by prompt type
if 'prompt_name' in test_df.columns:
    print("\nPerformance analysis by prompt type:")
    # Create a copy of test_df with predictions
    test_with_preds = test_df.copy()
    test_with_preds['predicted'] = test_preds
    test_with_preds['correct'] = test_with_preds['generated'] == test_with_preds['predicted']

    # Analyze by prompt name
    prompt_accuracy = test_with_preds.groupby('prompt_name')['correct'].mean()
    prompt_counts = test_with_preds.groupby('prompt_name').size()
    prompt_performance = pd.DataFrame({
        'accuracy': prompt_accuracy,
        'count': prompt_counts
    }).sort_values('accuracy')

    print(prompt_performance)

    # Visualize
    plt.figure(figsize=(12, 8))
    ax = prompt_performance['accuracy'].plot(kind='barh')
    ax.set_xlim(0, 1)
    ax.set_xlabel('Accuracy')
    ax.set_title('Model Accuracy by Prompt Type')
    plt.tight_layout()
    plt.savefig('prompt_performance.png')

    print("4. prompt_performance.png - Accuracy by prompt type")